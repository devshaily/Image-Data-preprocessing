{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e486c-b39a-41f9-98b8-134bf1a9c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade albumentations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766b7711-37ad-4f8d-9eed-4ebaf3b667c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "print(\"Albumentations and OpenCV are working ‚úÖ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050265d9-763e-4aec-906f-96eee304869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For augmentation of delam images \n",
    "import albumentations as A\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# --- Augmentation setup ---\n",
    "def get_transform():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Blur(blur_limit=3, p=0.2)\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "# --- Paths ---\n",
    "image_dir = r\"C:/Users/flexi/DeepL/New_Detection1/images/train\"\n",
    "label_dir = r\"C:/Users/flexi/DeepL/New_Detection1/labels/train\"\n",
    "aug_img_dir = r\"C:/Users/flexi/DeepL/New_Aug/aug_images\"\n",
    "aug_lbl_dir = r\"C:/Users/flexi/DeepL/New_Aug/aug_labels\"\n",
    "\n",
    "os.makedirs(aug_img_dir, exist_ok=True)\n",
    "os.makedirs(aug_lbl_dir, exist_ok=True)\n",
    "\n",
    "# --- Delamination filter ---\n",
    "def find_d_images(directory):\n",
    "    pattern = re.compile(r\".*_D\\d+\\.(?:jpg|jpeg|png|bmp|gif|webp)$\", re.IGNORECASE)\n",
    "    return [fname for fname in os.listdir(directory) if pattern.search(fname.strip())]\n",
    "\n",
    "delam_images = find_d_images(image_dir)\n",
    "\n",
    "print(f\"\\n[INFO] Found {len(delam_images)} matching delamination images:\")\n",
    "for img in sorted(delam_images):\n",
    "    print(f\" - {img}\")\n",
    "\n",
    "augmented_count = 0\n",
    "\n",
    "# --- Augmentation loop ---\n",
    "for fname in delam_images:\n",
    "    img_path = os.path.join(image_dir, fname)\n",
    "    label_path = os.path.join(label_dir, os.path.splitext(fname)[0] + \".txt\")\n",
    "\n",
    "    if not os.path.exists(label_path):\n",
    "        print(f\"[!] Label missing for {fname}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        print(f\"[!] Failed to load {fname}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    # Load YOLO-format bounding boxes with validation\n",
    "    bboxes, classes = [], []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                print(f\"[!] Invalid label in {fname}, skipping line.\")\n",
    "                continue\n",
    "\n",
    "            cls, x, y, bw, bh = map(float, parts)\n",
    "            x = np.clip(x, 0.0, 1.0)\n",
    "            y = np.clip(y, 0.0, 1.0)\n",
    "            bw = np.clip(bw, 0.0, 1.0 - x)\n",
    "            bh = np.clip(bh, 0.0, 1.0 - y)\n",
    "            bboxes.append([x, y, bw, bh])\n",
    "            classes.append(int(cls))\n",
    "\n",
    "    if not bboxes:\n",
    "        print(f\"[!] No valid bounding boxes in {fname}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Generate two augmented versions\n",
    "    for i in range(2):\n",
    "        try:\n",
    "            transformed = get_transform()(image=image, bboxes=bboxes, class_labels=classes)\n",
    "            aug_image = transformed['image']\n",
    "            aug_bboxes = transformed['bboxes']\n",
    "            aug_classes = transformed['class_labels']\n",
    "\n",
    "            if not aug_bboxes:\n",
    "                print(f\"[!] No bboxes after augmentation {i+1} for {fname}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Save augmented image and label\n",
    "            base_name = os.path.splitext(fname)[0] + f\"_aug{i+1}\"\n",
    "            out_img_path = os.path.join(aug_img_dir, base_name + \".jpg\")\n",
    "            out_lbl_path = os.path.join(aug_lbl_dir, base_name + \".txt\")\n",
    "\n",
    "            cv2.imwrite(out_img_path, aug_image)\n",
    "\n",
    "            with open(out_lbl_path, 'w') as f:\n",
    "                for cls, bbox in zip(aug_classes, aug_bboxes):\n",
    "                    x, y, bw, bh = bbox\n",
    "                    x = max(0.0, min(1.0, x))\n",
    "                    y = max(0.0, min(1.0, y))\n",
    "                    bw = max(0.0, min(1.0 - x, bw))\n",
    "                    bh = max(0.0, min(1.0 - y, bh))\n",
    "                    if bw < 0.01 or bh < 0.01:\n",
    "                        print(f\"[!] Skipping very small box in {fname} aug{i+1}\")\n",
    "                        continue\n",
    "                    f.write(f\"{cls} {x:.6f} {y:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
    "\n",
    "            print(f\"[‚úì] Augmented: {base_name}.jpg, Labels: {base_name}.txt\")\n",
    "            augmented_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[X] Error augmenting {fname} (aug{i+1}): {str(e)}\")\n",
    "\n",
    "print(f\"\\n[INFO] Total delamination images augmented: {augmented_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff84ebc8-ca91-48b8-9df6-8a9dfc8b437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access delam images count\n",
    "import os\n",
    "import re\n",
    "\n",
    "def find_d_images(directory):\n",
    "    \"\"\"\n",
    "    Find all image files with pattern _D followed by digits and image extension.\n",
    "    \n",
    "    Args:\n",
    "        directory: Path to search for images\n",
    "        \n",
    "    Returns:\n",
    "        List of matching filenames\n",
    "    \"\"\"\n",
    "    # More comprehensive pattern that:\n",
    "    # 1. Allows optional prefixes/suffixes\n",
    "    # 2. Handles multiple image extensions\n",
    "    # 3. Is case insensitive\n",
    "    # 4. Accounts for possible .jpg variations\n",
    "    pattern = re.compile(\n",
    "       r\".*_C\\d+.*\\.(?:jpg|jpeg|png|bmp|gif|webp)$\", \n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    matched_images = []\n",
    "    for fname in os.listdir(directory):\n",
    "        if pattern.search(fname.strip()):\n",
    "            matched_images.append(fname)\n",
    "    \n",
    "    return matched_images\n",
    "\n",
    "# Example usage\n",
    "image_dir = r\"C:/Users/flexi/DeepL/processed_dataset/images\"\n",
    "matches = find_d_images(image_dir)\n",
    "\n",
    "print(f\"Found {len(matches)} matching images:\")\n",
    "for img in sorted(matches):\n",
    "    print(f\" - {img}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517397d5-d5a6-4ffa-afb0-f1caf83dd437",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f9ef69-9a06-4245-8b9d-74f44b09d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to verify annotations with original image compaison but doesnt save\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "def load_image_and_labels(img_path, label_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    bboxes, classes = [], []\n",
    "    if not os.path.exists(label_path) or image is None:\n",
    "        return image, bboxes, classes\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                cls, x, y, bw, bh = map(float, parts)\n",
    "                bboxes.append([x, y, bw, bh])\n",
    "                classes.append(int(cls))\n",
    "    return image, bboxes, classes\n",
    "\n",
    "def draw_yolo_bboxes(image, bboxes, labels=None, color=(0, 255, 0)):\n",
    "    if image is None:\n",
    "        return None\n",
    "    h, w = image.shape[:2]\n",
    "    img = image.copy()\n",
    "    for i, (x, y, bw, bh) in enumerate(bboxes):\n",
    "        x1 = int((x - bw / 2) * w)\n",
    "        y1 = int((y - bh / 2) * h)\n",
    "        x2 = int((x + bw / 2) * w)\n",
    "        y2 = int((y + bh / 2) * h)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        if labels:\n",
    "            cv2.putText(img, str(labels[i]), (x1, y1 - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "    return img\n",
    "\n",
    "def show_images_with_annotations(base_filename, orig_img_dir, orig_lbl_dir, aug_img_dir, aug_lbl_dir):\n",
    "    paths = {\n",
    "        \"Original\": (os.path.join(orig_img_dir, base_filename + \".jpg\"),\n",
    "                     os.path.join(orig_lbl_dir, base_filename + \".txt\")),\n",
    "        \"Aug1\": (os.path.join(aug_img_dir, base_filename + \"_aug1.jpg\"),\n",
    "                 os.path.join(aug_lbl_dir, base_filename + \"_aug1.txt\")),\n",
    "        \"Aug2\": (os.path.join(aug_img_dir, base_filename + \"_aug2.jpg\"),\n",
    "                 os.path.join(aug_lbl_dir, base_filename + \"_aug2.txt\")),\n",
    "    }\n",
    "\n",
    "    images = []\n",
    "    titles = []\n",
    "\n",
    "    for title, (img_path, lbl_path) in paths.items():\n",
    "        img, bboxes, classes = load_image_and_labels(img_path, lbl_path)\n",
    "        if img is not None:\n",
    "            color = (0, 255, 0) if title == \"Original\" else (255, 0, 0) if title == \"Aug1\" else (0, 0, 255)\n",
    "            drawn = draw_yolo_bboxes(img, bboxes, classes, color=color)\n",
    "            images.append(drawn)\n",
    "            titles.append(f\"{base_filename}{'_aug1' if title == 'Aug1' else '_aug2' if title == 'Aug2' else ''}.jpg\")\n",
    "\n",
    "    if images:\n",
    "        fig, axs = plt.subplots(1, len(images), figsize=(6 * len(images), 6))\n",
    "        if len(images) == 1:\n",
    "            axs = [axs]\n",
    "        for ax, img, title in zip(axs, images, titles):\n",
    "            ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            ax.set_title(title)\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"[!] No valid images found for {base_filename}\")\n",
    "\n",
    "def find_delamination_images(folder):\n",
    "    pattern = re.compile(r\".*_D\\d+\\.(jpg|jpeg|png|bmp)$\", re.IGNORECASE)\n",
    "    return [f for f in os.listdir(folder) if pattern.match(f)]\n",
    "\n",
    "# --- Update these paths ---\n",
    "orig_img_dir = r\"C:/Users/flexi/DeepL/New_Detection1/images/train\"\n",
    "orig_lbl_dir = r\"C:/Users/flexi/DeepL/New_Detection1/labels/train\"\n",
    "aug_img_dir = r\"C:/Users/flexi/DeepL/New_Aug/aug_images\"\n",
    "aug_lbl_dir = r\"C:/Users/flexi/DeepL/New_Aug/aug_labels\"\n",
    "\n",
    "# --- Loop through all delamination images ---\n",
    "delam_images = find_delamination_images(orig_img_dir)\n",
    "\n",
    "print(f\"[INFO] Found {len(delam_images)} delamination images to visualize...\\n\")\n",
    "\n",
    "for fname in sorted(delam_images):\n",
    "    base_name = os.path.splitext(fname)[0]\n",
    "    print(f\"\\nüì∑ Showing: {base_name}\")\n",
    "    show_images_with_annotations(base_name, orig_img_dir, orig_lbl_dir, aug_img_dir, aug_lbl_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b3f151-1014-47c4-9e77-ef076d2ec77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to augment 92 images fpor crack too\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# --- Augmentation setup ---\n",
    "def get_transform():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Blur(blur_limit=3, p=0.2)\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "# --- Paths ---\n",
    "image_dir = r\"C:/Users/flexi/DeepL/New_Detection1/images/train\"\n",
    "label_dir = r\"C:/Users/flexi/DeepL/New_Detection1/labels/train\"\n",
    "aug_img_dir = r\"C:/Users/flexi/DeepL/New_Aug_C/aug_images\"\n",
    "aug_lbl_dir = r\"C:/Users/flexi/DeepL/New_Aug_C/aug_labels\"\n",
    "\n",
    "os.makedirs(aug_img_dir, exist_ok=True)\n",
    "os.makedirs(aug_lbl_dir, exist_ok=True)\n",
    "\n",
    "# --- Crack filter for \"_C\" ---\n",
    "def find_c_images(directory):\n",
    "    pattern = re.compile(r\".*_C\\d+\\.(?:jpg|jpeg|png|bmp|gif|webp)$\", re.IGNORECASE)\n",
    "    return sorted([fname for fname in os.listdir(directory) if pattern.search(fname.strip())])\n",
    "\n",
    "crack_images = find_c_images(image_dir)[:100]\n",
    "\n",
    "print(f\"\\n[INFO] Found {len(crack_images)} crack images:\")\n",
    "for img in crack_images:\n",
    "    print(f\" - {img}\")\n",
    "\n",
    "augmented_count = 0\n",
    "\n",
    "for fname in crack_images:\n",
    "    img_path = os.path.join(image_dir, fname)\n",
    "    label_path = os.path.join(label_dir, os.path.splitext(fname)[0] + \".txt\")\n",
    "\n",
    "    if not os.path.exists(label_path):\n",
    "        print(f\"[!] Label missing for {fname}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        print(f\"[!] Failed to load {fname}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    # Load YOLO-format bounding boxes with validation\n",
    "    bboxes, classes = [], []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                print(f\"[!] Invalid label in {fname}, skipping line.\")\n",
    "                continue\n",
    "\n",
    "            cls, x, y, bw, bh = map(float, parts)\n",
    "            x = np.clip(x, 0.0, 1.0)\n",
    "            y = np.clip(y, 0.0, 1.0)\n",
    "            bw = np.clip(bw, 0.0, 1.0 - x)\n",
    "            bh = np.clip(bh, 0.0, 1.0 - y)\n",
    "            bboxes.append([x, y, bw, bh])\n",
    "            classes.append(int(cls))\n",
    "\n",
    "    if not bboxes:\n",
    "        print(f\"[!] No valid bounding boxes in {fname}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        transformed = get_transform()(image=image, bboxes=bboxes, class_labels=classes)\n",
    "        aug_image = transformed['image']\n",
    "        aug_bboxes = transformed['bboxes']\n",
    "        aug_classes = transformed['class_labels']\n",
    "\n",
    "        if not aug_bboxes:\n",
    "            print(f\"[!] No bboxes after augmentation for {fname}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        base_name = os.path.splitext(fname)[0] + f\"_aug\"\n",
    "        out_img_path = os.path.join(aug_img_dir, base_name + \".jpg\")\n",
    "        out_lbl_path = os.path.join(aug_lbl_dir, base_name + \".txt\")\n",
    "\n",
    "        cv2.imwrite(out_img_path, aug_image)\n",
    "\n",
    "        with open(out_lbl_path, 'w') as f:\n",
    "            for cls, bbox in zip(aug_classes, aug_bboxes):\n",
    "                x, y, bw, bh = bbox\n",
    "                x = max(0.0, min(1.0, x))\n",
    "                y = max(0.0, min(1.0, y))\n",
    "                bw = max(0.0, min(1.0 - x, bw))\n",
    "                bh = max(0.0, min(1.0 - y, bh))\n",
    "                if bw < 0.01 or bh < 0.01:\n",
    "                    print(f\"[!] Skipping very small box in {fname} aug\")\n",
    "                    continue\n",
    "                f.write(f\"{cls} {x:.6f} {y:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
    "\n",
    "        print(f\"[‚úì] Augmented: {base_name}.jpg, Labels: {base_name}.txt\")\n",
    "        augmented_count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[X] Error augmenting {fname}: {str(e)}\")\n",
    "\n",
    "print(f\"\\n[INFO] Total crack images augmented: {augmented_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbb5a3-72e1-4c84-b9e5-0159afd42327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image size check\n",
    "import os\n",
    "import cv2\n",
    "from collections import Counter\n",
    "\n",
    "# --- Set your image directory ---\n",
    "image_dir = r\"C:/Users/flexi/DeepL/New_Detection1/images/train\"  # update if needed\n",
    "\n",
    "# --- Supported image extensions ---\n",
    "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\", \".tiff\"}\n",
    "\n",
    "# --- Initialize variables ---\n",
    "size_counter = Counter()\n",
    "widths, heights = [], []\n",
    "total_images = 0\n",
    "\n",
    "# --- Walk through the directory ---\n",
    "for fname in os.listdir(image_dir):\n",
    "    ext = os.path.splitext(fname)[1].lower()\n",
    "    if ext not in image_extensions:\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(image_dir, fname)\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"[!] Could not read: {fname}\")\n",
    "        continue\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    size_counter[(w, h)] += 1\n",
    "    widths.append(w)\n",
    "    heights.append(h)\n",
    "    total_images += 1\n",
    "\n",
    "# --- Results ---\n",
    "print(\"\\nüìè Image Size Analysis\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Total images analyzed: {total_images}\\n\")\n",
    "\n",
    "print(\"üßÆ Size Frequency:\")\n",
    "for size, count in size_counter.most_common():\n",
    "    print(f\" - {size[0]}x{size[1]} : {count} image(s)\")\n",
    "\n",
    "if widths and heights:\n",
    "    print(f\"\\nüîç Minimum Width: {min(widths)} px\")\n",
    "    print(f\"üîç Maximum Width: {max(widths)} px\")\n",
    "    print(f\"üîç Minimum Height: {min(heights)} px\")\n",
    "    print(f\"üîç Maximum Height: {max(heights)} px\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e26e65-e63b-460b-ae0c-7b9f054552cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize and padding with annotation\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "# üóÇÔ∏è Paths\n",
    "input_image_dir = r'C:/Users/flexi/DeepL/New_Detection1/images/train'\n",
    "input_label_dir = r'C:/Users/flexi/DeepL/New_Detection1/labels/train'\n",
    "\n",
    "output_image_dir = r'C:/Users/flexi/DeepL/New_Detection1/processed_dataset/images'\n",
    "output_label_dir = r'C:/Users/flexi/DeepL/New_Detection1/processed_dataset/labels'\n",
    "\n",
    "os.makedirs(output_image_dir, exist_ok=True)\n",
    "os.makedirs(output_label_dir, exist_ok=True)\n",
    "\n",
    "TARGET_SIZE = 2048  # Square dimension\n",
    "PADDING_COLOR = (0, 0, 0)  # Black\n",
    "\n",
    "def resize_and_pad_image(image):\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Resize if either dim > 2048\n",
    "    scale = min(TARGET_SIZE / w, TARGET_SIZE / h)\n",
    "    resized = cv2.resize(image, (int(w * scale), int(h * scale)))\n",
    "\n",
    "    new_h, new_w = resized.shape[:2]\n",
    "    pad_top = (TARGET_SIZE - new_h) // 2\n",
    "    pad_bottom = TARGET_SIZE - new_h - pad_top\n",
    "    pad_left = (TARGET_SIZE - new_w) // 2\n",
    "    pad_right = TARGET_SIZE - new_w - pad_left\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, pad_top, pad_bottom, pad_left, pad_right,\n",
    "                                borderType=cv2.BORDER_CONSTANT, value=PADDING_COLOR)\n",
    "    \n",
    "    return padded, scale, pad_left, pad_top, w, h\n",
    "\n",
    "def adjust_yolo_labels(label_path, output_path, scale, pad_left, pad_top, orig_w, orig_h):\n",
    "    if not os.path.exists(label_path):\n",
    "        return\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    updated_lines = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5:\n",
    "            continue\n",
    "\n",
    "        cls, x_center, y_center, box_w, box_h = map(float, parts)\n",
    "\n",
    "        # Convert from relative to absolute\n",
    "        abs_x = x_center * orig_w\n",
    "        abs_y = y_center * orig_h\n",
    "        abs_w = box_w * orig_w\n",
    "        abs_h = box_h * orig_h\n",
    "\n",
    "        # Scale and pad\n",
    "        abs_x = abs_x * scale + pad_left\n",
    "        abs_y = abs_y * scale + pad_top\n",
    "        abs_w *= scale\n",
    "        abs_h *= scale\n",
    "\n",
    "        # Convert back to relative (new size = 2048)\n",
    "        rel_x = abs_x / TARGET_SIZE\n",
    "        rel_y = abs_y / TARGET_SIZE\n",
    "        rel_w = abs_w / TARGET_SIZE\n",
    "        rel_h = abs_h / TARGET_SIZE\n",
    "\n",
    "        updated_line = f\"{int(cls)} {rel_x:.6f} {rel_y:.6f} {rel_w:.6f} {rel_h:.6f}\"\n",
    "        updated_lines.append(updated_line)\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('\\n'.join(updated_lines))\n",
    "\n",
    "\n",
    "# üöÄ Process images\n",
    "image_extensions = ['.jpg', '.jpeg', '.png']\n",
    "\n",
    "for filename in os.listdir(input_image_dir):\n",
    "    if not any(filename.lower().endswith(ext) for ext in image_extensions):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(input_image_dir, filename)\n",
    "    label_path = os.path.join(input_label_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    padded_img, scale, pad_left, pad_top, orig_w, orig_h = resize_and_pad_image(img)\n",
    "\n",
    "    out_img_path = os.path.join(output_image_dir, filename)\n",
    "    out_label_path = os.path.join(output_label_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "\n",
    "    cv2.imwrite(out_img_path, padded_img)\n",
    "    adjust_yolo_labels(label_path, out_label_path, scale, pad_left, pad_top, orig_w, orig_h)\n",
    "\n",
    "print(\"‚úÖ Done! All images and labels saved in 'processed_dataset/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461bff10-0a6d-4e0f-8ab4-87023155ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating annotated images to verify\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Paths\n",
    "image_dir = r\"C:\\Users\\flexi\\DeepL\\processed_dataset\\images\"\n",
    "label_dir = r\"C:\\Users\\flexi\\DeepL\\processed_dataset\\labels\"\n",
    "output_dir = r\"C:\\Users\\flexi\\DeepL\\processed_dataset\\annotated_images\"\n",
    "\n",
    "# Make output dir if not exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Class names (change if needed)\n",
    "class_names = ['Delamination', 'Crack']\n",
    "\n",
    "# Color mapping for classes\n",
    "class_colors = {\n",
    "    0: (0, 255, 0),  # Green for Crack\n",
    "    1: (0, 0, 255)   # Red for Delamination\n",
    "}\n",
    "\n",
    "# Iterate over images\n",
    "for image_name in os.listdir(image_dir):\n",
    "    if not image_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.webp')):\n",
    "        continue\n",
    "\n",
    "    # Load image\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"‚ö†Ô∏è Couldn't read image: {image_name}\")\n",
    "        continue\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Corresponding label\n",
    "    label_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "    label_path = os.path.join(label_dir, label_name)\n",
    "\n",
    "    if not os.path.exists(label_path):\n",
    "        print(f\"‚ùå Missing label for: {image_name}\")\n",
    "        continue\n",
    "\n",
    "    # Read label file\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                print(f\"‚ö†Ô∏è Invalid label format in {label_name}\")\n",
    "                continue\n",
    "            cls_id, xc, yc, bw, bh = map(float, parts)\n",
    "            cls_id = int(cls_id)\n",
    "\n",
    "            # Convert YOLO format to pixel coords\n",
    "            x1 = int((xc - bw / 2) * w)\n",
    "            y1 = int((yc - bh / 2) * h)\n",
    "            x2 = int((xc + bw / 2) * w)\n",
    "            y2 = int((yc + bh / 2) * h)\n",
    "\n",
    "            # Draw bounding box\n",
    "            color = class_colors.get(cls_id, (255, 255, 255))\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "            # Add class label\n",
    "            label_text = class_names[cls_id] if cls_id < len(class_names) else f'Class {cls_id}'\n",
    "            cv2.putText(img, label_text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "    # Save annotated image\n",
    "    out_path = os.path.join(output_dir, image_name)\n",
    "    cv2.imwrite(out_path, img)\n",
    "\n",
    "print(\"\\n‚úÖ All images annotated and saved!\")\n",
    "print(f\"Check folder: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06b41c77-ed8b-40c8-b15b-fdb93bea1694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Crack images...\n",
      "Found 340 original and 92 augmented Crack images\n",
      "Processing Delamination images...\n",
      "Found 148 original and 284 augmented Delamination images\n",
      "Copying files...\n",
      "\n",
      "Dataset split summary:\n",
      "Split\tClass\tOrig\tAug\tTotal\n",
      "Crack\tTrain\t238\t64\t302\n",
      "Crack\tVal\t68\t18\t86\n",
      "Crack\tTest\t34\t10\t44\n",
      "\n",
      "Delamination\tTrain\t104\t198\t302\n",
      "Delamination\tVal\t30\t56\t86\n",
      "Delamination\tTest\t14\t30\t44\n",
      "\n",
      "\n",
      "‚úÖ Dataset split completed according to specified table!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_class_images(directory, class_tag):\n",
    "    \"\"\"\n",
    "    Find all image files for a specific class (Crack or Delamination)\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\n",
    "        rf\".*_{class_tag}\\d+.*\\.(?:jpg|jpeg|png|bmp|gif|webp)$\", \n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    return [f for f in os.listdir(directory) if pattern.search(f)]\n",
    "\n",
    "def separate_original_augmented(image_list):\n",
    "    \"\"\"\n",
    "    Separate original images from augmented images based on the specific naming pattern\n",
    "    \"\"\"\n",
    "    original = []\n",
    "    augmented = []\n",
    "    \n",
    "    for img in image_list:\n",
    "        # Original images end with _C# or _D# without any suffix\n",
    "        if re.search(r'_[CD]\\d+\\.', img):  # Ends with _C1.jpg or _D31.jpg\n",
    "            original.append(img)\n",
    "        # Augmented images have _aug or _aug# after the class number\n",
    "        elif re.search(r'_[CD]\\d+_aug\\d*\\.', img):  # Matches _C1_aug.jpg or _D31_aug2.jpg\n",
    "            augmented.append(img)\n",
    "    \n",
    "    return original, augmented\n",
    "\n",
    "def split_dataset(original, augmented, train_orig, train_aug, val_orig, val_aug, test_orig, test_aug):\n",
    "    \"\"\"\n",
    "    Split dataset into train, val, test with specified counts for original and augmented\n",
    "    \"\"\"\n",
    "    # Verify we have enough images\n",
    "    assert len(original) >= train_orig + val_orig + test_orig, \"Not enough original images\"\n",
    "    assert len(augmented) >= train_aug + val_aug + test_aug, \"Not enough augmented images\"\n",
    "    \n",
    "    # Shuffle both lists\n",
    "    random.shuffle(original)\n",
    "    random.shuffle(augmented)\n",
    "    \n",
    "    # Split original images\n",
    "    orig_train = original[:train_orig]\n",
    "    orig_val = original[train_orig:train_orig+val_orig]\n",
    "    orig_test = original[train_orig+val_orig:train_orig+val_orig+test_orig]\n",
    "    \n",
    "    # Split augmented images\n",
    "    aug_train = augmented[:train_aug]\n",
    "    aug_val = augmented[train_aug:train_aug+val_aug]\n",
    "    aug_test = augmented[train_aug+val_aug:train_aug+val_aug+test_aug]\n",
    "    \n",
    "    # Combine original and augmented for each split\n",
    "    train_files = orig_train + aug_train\n",
    "    val_files = orig_val + aug_val\n",
    "    test_files = orig_test + aug_test\n",
    "    \n",
    "    return train_files, val_files, test_files\n",
    "\n",
    "def copy_files(file_list, src_img_dir, src_lbl_dir, dst_img_dir, dst_lbl_dir):\n",
    "    \"\"\"\n",
    "    Copy image and label files to destination directories\n",
    "    \"\"\"\n",
    "    os.makedirs(dst_img_dir, exist_ok=True)\n",
    "    os.makedirs(dst_lbl_dir, exist_ok=True)\n",
    "    \n",
    "    for fname in file_list:\n",
    "        # Copy image\n",
    "        shutil.copy2(os.path.join(src_img_dir, fname), os.path.join(dst_img_dir, fname))\n",
    "        \n",
    "        # Copy corresponding label\n",
    "        label = os.path.splitext(fname)[0] + \".txt\"\n",
    "        lbl_src = os.path.join(src_lbl_dir, label)\n",
    "        if os.path.exists(lbl_src):\n",
    "            shutil.copy2(lbl_src, os.path.join(dst_lbl_dir, label))\n",
    "\n",
    "def print_split_summary(class_name, train, val, test):\n",
    "    \"\"\"\n",
    "    Print summary of the split for a class\n",
    "    \"\"\"\n",
    "    train_orig = len([f for f in train if not re.search(r'_[CD]\\d+_aug\\d*\\.', f)])\n",
    "    train_aug = len(train) - train_orig\n",
    "    \n",
    "    val_orig = len([f for f in val if not re.search(r'_[CD]\\d+_aug\\d*\\.', f)])\n",
    "    val_aug = len(val) - val_orig\n",
    "    \n",
    "    test_orig = len([f for f in test if not re.search(r'_[CD]\\d+_aug\\d*\\.', f)])\n",
    "    test_aug = len(test) - test_orig\n",
    "    \n",
    "    print(f\"{class_name}\\tTrain\\t{train_orig}\\t{train_aug}\\t{len(train)}\")\n",
    "    print(f\"{class_name}\\tVal\\t{val_orig}\\t{val_aug}\\t{len(val)}\")\n",
    "    print(f\"{class_name}\\tTest\\t{test_orig}\\t{test_aug}\\t{len(test)}\")\n",
    "    print()\n",
    "\n",
    "# === PATHS ===\n",
    "input_image_dir = r'C:/Users/flexi/DeepL/processed_dataset/images'\n",
    "input_label_dir = r'C:/Users/flexi/DeepL/processed_dataset/labels'\n",
    "output_base_dir = r\"C:/Users/flexi/DeepL/final_split_dataset\"\n",
    "\n",
    "# === SPLIT CONFIGURATION ===\n",
    "# Crack split configuration\n",
    "crack_split = {\n",
    "    'train_orig': 238,\n",
    "    'train_aug': 64,\n",
    "    'val_orig': 68,\n",
    "    'val_aug': 18,\n",
    "    'test_orig': 34,\n",
    "    'test_aug': 10\n",
    "}\n",
    "\n",
    "# Delamination split configuration\n",
    "delam_split = {\n",
    "    'train_orig': 104,\n",
    "    'train_aug': 198,\n",
    "    'val_orig': 30,\n",
    "    'val_aug': 56,\n",
    "    'test_orig': 14,\n",
    "    'test_aug': 30\n",
    "}\n",
    "\n",
    "# === PROCESS CRACK IMAGES ===\n",
    "print(\"Processing Crack images...\")\n",
    "crack_images = find_class_images(input_image_dir, 'C')\n",
    "crack_orig, crack_aug = separate_original_augmented(crack_images)\n",
    "\n",
    "print(f\"Found {len(crack_orig)} original and {len(crack_aug)} augmented Crack images\")\n",
    "\n",
    "crack_train, crack_val, crack_test = split_dataset(\n",
    "    crack_orig, crack_aug,\n",
    "    crack_split['train_orig'], crack_split['train_aug'],\n",
    "    crack_split['val_orig'], crack_split['val_aug'],\n",
    "    crack_split['test_orig'], crack_split['test_aug']\n",
    ")\n",
    "\n",
    "# === PROCESS DELAMINATION IMAGES ===\n",
    "print(\"Processing Delamination images...\")\n",
    "delam_images = find_class_images(input_image_dir, 'D')\n",
    "delam_orig, delam_aug = separate_original_augmented(delam_images)\n",
    "\n",
    "print(f\"Found {len(delam_orig)} original and {len(delam_aug)} augmented Delamination images\")\n",
    "\n",
    "delam_train, delam_val, delam_test = split_dataset(\n",
    "    delam_orig, delam_aug,\n",
    "    delam_split['train_orig'], delam_split['train_aug'],\n",
    "    delam_split['val_orig'], delam_split['val_aug'],\n",
    "    delam_split['test_orig'], delam_split['test_aug']\n",
    ")\n",
    "\n",
    "# === COPY FILES TO DESTINATION ===\n",
    "print(\"Copying files...\")\n",
    "\n",
    "# Crack files\n",
    "copy_files(crack_train, input_image_dir, input_label_dir,\n",
    "           os.path.join(output_base_dir, 'train', 'images'),\n",
    "           os.path.join(output_base_dir, 'train', 'labels'))\n",
    "\n",
    "copy_files(crack_val, input_image_dir, input_label_dir,\n",
    "           os.path.join(output_base_dir, 'val', 'images'),\n",
    "           os.path.join(output_base_dir, 'val', 'labels'))\n",
    "\n",
    "copy_files(crack_test, input_image_dir, input_label_dir,\n",
    "           os.path.join(output_base_dir, 'test', 'images'),\n",
    "           os.path.join(output_base_dir, 'test', 'labels'))\n",
    "\n",
    "# Delamination files\n",
    "copy_files(delam_train, input_image_dir, input_label_dir,\n",
    "           os.path.join(output_base_dir, 'train', 'images'),\n",
    "           os.path.join(output_base_dir, 'train', 'labels'))\n",
    "\n",
    "copy_files(delam_val, input_image_dir, input_label_dir,\n",
    "           os.path.join(output_base_dir, 'val', 'images'),\n",
    "           os.path.join(output_base_dir, 'val', 'labels'))\n",
    "\n",
    "copy_files(delam_test, input_image_dir, input_label_dir,\n",
    "           os.path.join(output_base_dir, 'test', 'images'),\n",
    "           os.path.join(output_base_dir, 'test', 'labels'))\n",
    "\n",
    "# === PRINT SUMMARY ===\n",
    "print(\"\\nDataset split summary:\")\n",
    "print(\"Split\\tClass\\tOrig\\tAug\\tTotal\")\n",
    "print_split_summary(\"Crack\", crack_train, crack_val, crack_test)\n",
    "print_split_summary(\"Delamination\", delam_train, delam_val, delam_test)\n",
    "\n",
    "print(\"\\n‚úÖ Dataset split completed according to specified table!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a43a84-873b-4a0a-a26c-d981460be99e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
