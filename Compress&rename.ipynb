{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9675134c-fb89-4185-8a2b-8a1a73822604",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     56\u001b[39m use_webp = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     57\u001b[39m size_threshold_kb = \u001b[32m1000\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mbatch_compress_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_webp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_threshold_kb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mbatch_compress_images\u001b[39m\u001b[34m(input_folder, output_folder, quality, use_webp, size_threshold_kb)\u001b[39m\n\u001b[32m     33\u001b[39m original_size = get_file_size_kb(input_path)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m original_size > size_threshold_kb:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     before_size, after_size, saved_path = \u001b[43mcompress_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_webp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m before_size \u001b[38;5;129;01mand\u001b[39;00m after_size:\n\u001b[32m     37\u001b[39m         results.append((filename, before_size, after_size, saved_path))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mcompress_image\u001b[39m\u001b[34m(input_path, output_path, quality, use_webp)\u001b[39m\n\u001b[32m     15\u001b[39m             img.save(output_path, \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mWEBP\u001b[39m\u001b[33m'\u001b[39m, quality=quality, method=\u001b[32m6\u001b[39m)\n\u001b[32m     16\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m             \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mJPEG\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m get_file_size_kb(input_path), get_file_size_kb(output_path), output_path\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\PIL\\Image.py:2581\u001b[39m, in \u001b[36mImage.save\u001b[39m\u001b[34m(self, fp, format, **params)\u001b[39m\n\u001b[32m   2578\u001b[39m     fp = cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[32m   2580\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2581\u001b[39m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2582\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   2583\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\PIL\\JpegImagePlugin.py:853\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, filename)\u001b[39m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    849\u001b[39m     \u001b[38;5;66;03m# The EXIF info needs to be written as one block, + APP1, + one spare byte.\u001b[39;00m\n\u001b[32m    850\u001b[39m     \u001b[38;5;66;03m# Ensure that our buffer is big enough. Same with the icc_profile block.\u001b[39;00m\n\u001b[32m    851\u001b[39m     bufsize = \u001b[38;5;28mmax\u001b[39m(bufsize, \u001b[38;5;28mlen\u001b[39m(exif) + \u001b[32m5\u001b[39m, \u001b[38;5;28mlen\u001b[39m(extra) + \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m853\u001b[39m \u001b[43mImageFile\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mImageFile\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Tile\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjpeg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\PIL\\ImageFile.py:645\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, tile, bufsize)\u001b[39m\n\u001b[32m    643\u001b[39m     fh = fp.fileno()\n\u001b[32m    644\u001b[39m     fp.flush()\n\u001b[32m--> \u001b[39m\u001b[32m645\u001b[39m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io.UnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    647\u001b[39m     _encode_tile(im, fp, tile, bufsize, \u001b[38;5;28;01mNone\u001b[39;00m, exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\PIL\\ImageFile.py:680\u001b[39m, in \u001b[36m_encode_tile\u001b[39m\u001b[34m(im, fp, tile, bufsize, fh, exc)\u001b[39m\n\u001b[32m    677\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    678\u001b[39m         \u001b[38;5;66;03m# slight speedup: compress to real file object\u001b[39;00m\n\u001b[32m    679\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m fh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m680\u001b[39m         errcode = \u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m errcode < \u001b[32m0\u001b[39m:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _get_oserror(errcode, encoder=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Image Compression Without Losing Quality (if > 1000 KB)\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def get_file_size_kb(path):\n",
    "    return round(os.path.getsize(path) / 1024, 2)\n",
    "\n",
    "def compress_image(input_path, output_path, quality=85, use_webp=False):\n",
    "    try:\n",
    "        with Image.open(input_path) as img:\n",
    "            img = img.convert(\"RGB\")  # Ensure compatible format\n",
    "\n",
    "            if use_webp:\n",
    "                output_path = output_path.rsplit('.', 1)[0] + \".webp\"\n",
    "                img.save(output_path, format='WEBP', quality=quality, method=6)\n",
    "            else:\n",
    "                img.save(output_path, format='JPEG', quality=quality, optimize=True)\n",
    "\n",
    "            return get_file_size_kb(input_path), get_file_size_kb(output_path), output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error compressing {input_path}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def batch_compress_images(input_folder, output_folder, quality=85, use_webp=False, size_threshold_kb=1000):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    results = []\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            original_size = get_file_size_kb(input_path)\n",
    "            if original_size > size_threshold_kb:\n",
    "                before_size, after_size, saved_path = compress_image(input_path, output_path, quality, use_webp)\n",
    "                if before_size and after_size:\n",
    "                    results.append((filename, before_size, after_size, saved_path))\n",
    "            else:\n",
    "                # Simply copy smaller images without compression\n",
    "                output_path = os.path.join(output_folder, filename)\n",
    "                with open(input_path, 'rb') as src, open(output_path, 'wb') as dst:\n",
    "                    dst.write(src.read())\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n{'Filename':30} {'Original (KB)':>15} {'Compressed (KB)':>18}\")\n",
    "    print(\"-\" * 65)\n",
    "    for fname, before, after, _ in results:\n",
    "        print(f\"{fname:30} {before:>15} {after:>18}\")\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = r\"D:\\ShailyDL\\DeepL\\345098_DS2\\images\\train\"\n",
    "    output_dir = r\"D:\\ShailyDL\\DeepL\\345098_DS2\\images\\train_compressed\"\n",
    "\n",
    "    quality = 85\n",
    "    use_webp = False\n",
    "    size_threshold_kb = 1000\n",
    "\n",
    "    batch_compress_images(input_dir, output_dir, quality, use_webp, size_threshold_kb)\n",
    "\n",
    "   #result  #Filename                         Original (KB)    Compressed (KB)\n",
    "#-----------------------------------------------------------------\n",
    "#1042487_dataset 2025-05-15 08-51-58_C1012.jpg         5841.71            5758.66\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd3263b3-1343-4e7b-95ad-3f8dfe49401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No match found in filename: annotations_test.json\n",
      "⚠️ No match found in filename: annotations_train.json\n",
      "⚠️ No match found in filename: annotations_val.json\n",
      "✅ Done renaming and copying.\n",
      "Total images processed: 864\n",
      "Total labels processed: 864\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# Source folders\n",
    "image_input_dir = r\"D:\\ShailyDL\\DeepL\\ds2_864\\images\"\n",
    "label_input_dir = r\"D:\\ShailyDL\\DeepL\\ds2_864\\labels\"\n",
    "\n",
    "# Destination folders\n",
    "image_output_dir = r\"D:\\ShailyDL\\DeepL\\NEW_DS_Cleaned\\images\"\n",
    "label_output_dir = r\"D:\\ShailyDL\\DeepL\\NEW_DS_Cleaned\\labels\"\n",
    "\n",
    "# Create destination folders if they don't exist\n",
    "os.makedirs(image_output_dir, exist_ok=True)\n",
    "os.makedirs(label_output_dir, exist_ok=True)\n",
    "\n",
    "# Regex: Match Cxxx, Dxxx, or Nodefect_xxx with optional _aug or _aug1\n",
    "pattern = re.compile(r'(C\\d+(?:_aug\\d*)?|D\\d+(?:_aug\\d*)?|Nodefect_\\d+)', re.IGNORECASE)\n",
    "\n",
    "def rename_and_copy_files(input_dir, output_dir, is_label=False):\n",
    "    count = 0\n",
    "    for file in os.listdir(input_dir):\n",
    "        match = pattern.search(file)\n",
    "        if match:\n",
    "            matched_part = match.group(1)\n",
    "            ext = \".txt\" if is_label else os.path.splitext(file)[1]\n",
    "            new_name = matched_part + ext\n",
    "            src = os.path.join(input_dir, file)\n",
    "            dst = os.path.join(output_dir, new_name)\n",
    "\n",
    "            # If file already exists, add a unique suffix\n",
    "            suffix = 1\n",
    "            while os.path.exists(dst):\n",
    "                new_name = f\"{matched_part}_{suffix}{ext}\"\n",
    "                dst = os.path.join(output_dir, new_name)\n",
    "                suffix += 1\n",
    "\n",
    "            shutil.copy2(src, dst)\n",
    "            count += 1\n",
    "        else:\n",
    "            print(f\"⚠️ No match found in filename: {file}\")\n",
    "    return count\n",
    "\n",
    "# Process\n",
    "images_copied = rename_and_copy_files(image_input_dir, image_output_dir, is_label=False)\n",
    "labels_copied = rename_and_copy_files(label_input_dir, label_output_dir, is_label=True)\n",
    "\n",
    "print(\"✅ Done renaming and copying.\")\n",
    "print(f\"Total images processed: {images_copied}\")\n",
    "print(f\"Total labels processed: {labels_copied}\")\n",
    "\n",
    "#result for all : Done renaming and copying.\n",
    "#Total images processed: 326\n",
    "#Total labels processed: 326\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bd8e1a6-72ae-4c0e-9c1a-39b386f7bdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done filtering and moving unmatched images and labels.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# Input folders\n",
    "image_input_dir = r\"D:\\ShailyDL\\DeepL\\345676_DS3 (2)\\images\\train\"\n",
    "label_input_dir = r\"D:\\ShailyDL\\DeepL\\345676_DS3 (2)\\labels\\train\"\n",
    "\n",
    "# Output folders for matched files (not used now)\n",
    "# image_output_dir = r\"D:\\ShailyDL\\DeepL\\NEW_DS_Cleaned\\images\"\n",
    "# label_output_dir = r\"D:\\ShailyDL\\DeepL\\NEW_DS_Cleaned\\labels\"\n",
    "\n",
    "# Output folders for unmatched files\n",
    "image_filtered_dir = r\"D:\\ShailyDL\\DeepL\\FilteredOut\\images\"\n",
    "label_filtered_dir = r\"D:\\ShailyDL\\DeepL\\FilteredOut\\labels\"\n",
    "\n",
    "# Create output dirs\n",
    "os.makedirs(image_filtered_dir, exist_ok=True)\n",
    "os.makedirs(label_filtered_dir, exist_ok=True)\n",
    "\n",
    "# Matching pattern\n",
    "pattern = re.compile(r'(C\\d+|D\\d+|Nodefect_\\d+)', re.IGNORECASE)\n",
    "\n",
    "def filter_and_copy_unmatched(input_dir, output_dir, is_label=False):\n",
    "    for file in os.listdir(input_dir):\n",
    "        match = pattern.search(file)\n",
    "        if not match:\n",
    "            src = os.path.join(input_dir, file)\n",
    "            dst = os.path.join(output_dir, file)\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "# Process unmatched images and labels\n",
    "filter_and_copy_unmatched(image_input_dir, image_filtered_dir, is_label=False)\n",
    "filter_and_copy_unmatched(label_input_dir, label_filtered_dir, is_label=True)\n",
    "\n",
    "print(\"✅ Done filtering and moving unmatched images and labels.\")\n",
    "\n",
    "#result: ✅ Done filtering and moving unmatched images and labels.code for those which are not renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b47eee41-97af-4d1d-bf99-e3afea0d613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OnlyDelami count: 326\n",
      "NoDefect count: 1362\n",
      "Others count: 480\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Directory to check\n",
    "image_dir = r\"D:\\ShailyDL\\DeepL\\345676_DS3 (2)\\images\\train\"\n",
    "\n",
    "# Regex patterns\n",
    "pattern_only_delami = re.compile(r'OnlyDelami', re.IGNORECASE)\n",
    "pattern_nodefect = re.compile(r'Nodefect', re.IGNORECASE)\n",
    "\n",
    "# Counters\n",
    "count_only_delami = 0\n",
    "count_nodefect = 0\n",
    "count_others = 0\n",
    "\n",
    "# Check if path exists\n",
    "if os.path.exists(image_dir):\n",
    "    for file in os.listdir(image_dir):\n",
    "        if pattern_only_delami.search(file):\n",
    "            count_only_delami += 1\n",
    "        elif pattern_nodefect.search(file):\n",
    "            count_nodefect += 1\n",
    "        else:\n",
    "            count_others += 1\n",
    "\n",
    "    print(f\"OnlyDelami count: {count_only_delami}\")\n",
    "    print(f\"NoDefect count: {count_nodefect}\")\n",
    "    print(f\"Others count: {count_others}\")\n",
    "else:\n",
    "    print(\"❌ The specified directory does not exist.\")\n",
    "\n",
    "  #result  #OnlyDelami count: 326\n",
    "#NoDefect count: 1362\n",
    "#Others count: 480\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a9852-05a6-456f-ba85-5b948357ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# Source folders\n",
    "image_input_dir = r\"D:\\ShailyDL\\DeepL\\345676_DS3 (2)\\images\\train\"\n",
    "label_input_dir = r\"D:\\ShailyDL\\DeepL\\345676_DS3 (2)\\labels\\train\"\n",
    "\n",
    "# Destination folders\n",
    "image_output_dir = r\"D:\\ShailyDL\\DeepL\\NEW_DS_Cleaned\\images\"\n",
    "label_output_dir = r\"D:\\ShailyDL\\DeepL\\NEW_DS_Cleaned\\labels\"\n",
    "\n",
    "# Create destination folders if they don't exist\n",
    "os.makedirs(image_output_dir, exist_ok=True)\n",
    "os.makedirs(label_output_dir, exist_ok=True)\n",
    "\n",
    "# Regex: Match Cxxx, Dxxx, or Nodefect_xxx with optional _aug or _aug1\n",
    "pattern = re.compile(r'(Nodefect_\\d*)', re.IGNORECASE)\n",
    "\n",
    "def rename_and_copy_files(input_dir, output_dir, is_label=False):\n",
    "    count = 0\n",
    "    for file in os.listdir(input_dir):\n",
    "        match = pattern.search(file)\n",
    "        if match:\n",
    "            matched_part = match.group(1)\n",
    "            ext = \".txt\" if is_label else os.path.splitext(file)[1]\n",
    "            new_name = matched_part + ext\n",
    "            src = os.path.join(input_dir, file)\n",
    "            dst = os.path.join(output_dir, new_name)\n",
    "\n",
    "            # If file already exists, add a unique suffix\n",
    "            suffix = 1\n",
    "            while os.path.exists(dst):\n",
    "                new_name = f\"{matched_part}_{suffix}{ext}\"\n",
    "                dst = os.path.join(output_dir, new_name)\n",
    "                suffix += 1\n",
    "\n",
    "            shutil.copy2(src, dst)\n",
    "            count += 1\n",
    "        else:\n",
    "            print(f\"⚠️ No match found in filename: {file}\")\n",
    "    return count\n",
    "\n",
    "# Process\n",
    "images_copied = rename_and_copy_files(image_input_dir, image_output_dir, is_label=False)\n",
    "labels_copied = rename_and_copy_files(label_input_dir, label_output_dir, is_label=True)\n",
    "\n",
    "print(\"✅ Done renaming and copying.\")\n",
    "print(f\"Total images processed: {images_copied}\")\n",
    "print(f\"Total labels processed: {labels_copied}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e36e92cb-634f-4d68-b249-f8d2c726aea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done filtering and moving unmatched images and labels.\n",
      "Unmatched images copied: 480\n",
      "Unmatched labels copied: 480\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# Input folders\n",
    "image_input_dir = r\"D:\\ShailyDL\\DeepL\\345676_DS3 (2)\\images\\train\"\n",
    "label_input_dir = r\"D:\\ShailyDL\\DeepL\\345676_DS3 (2)\\labels\\train\"\n",
    "\n",
    "# Output folders for unmatched (filtered) files\n",
    "image_filtered_dir = r\"D:\\ShailyDL\\DeepL\\FilteredOut\\images\"\n",
    "label_filtered_dir = r\"D:\\ShailyDL\\DeepL\\FilteredOut\\labels\"\n",
    "\n",
    "# Create output dirs\n",
    "os.makedirs(image_filtered_dir, exist_ok=True)\n",
    "os.makedirs(label_filtered_dir, exist_ok=True)\n",
    "\n",
    "# Correct pattern: match Cxxx, Dxxx, or Nodefect_xxx with optional _aug or _aug1\n",
    "pattern = re.compile(r'(C\\d+(?:_aug\\d*)?|D\\d+(?:_aug\\d*)?|Nodefect_\\d*)', re.IGNORECASE)\n",
    "\n",
    "def filter_and_copy_unmatched(input_dir, output_dir):\n",
    "    count = 0\n",
    "    for file in os.listdir(input_dir):\n",
    "        if not pattern.search(file):\n",
    "            src = os.path.join(input_dir, file)\n",
    "            dst = os.path.join(output_dir, file)\n",
    "            shutil.copy2(src, dst)\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# Process unmatched files\n",
    "unmatched_images = filter_and_copy_unmatched(image_input_dir, image_filtered_dir)\n",
    "unmatched_labels = filter_and_copy_unmatched(label_input_dir, label_filtered_dir)\n",
    "\n",
    "print(\"✅ Done filtering and moving unmatched images and labels.\")\n",
    "print(f\"Unmatched images copied: {unmatched_images}\")\n",
    "print(f\"Unmatched labels copied: {unmatched_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca89779-5abb-4d22-972c-7b13a0ea7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# Source folders\n",
    "image_input_dir = r\"D:\\ShailyDL\\DeepL\\345676_DS3 (2)\\images\\train\"\n",
    "label_input_dir = r\"D:\\ShailyDL\\DeepL\\345676_DS3 (2)\\labels\\train\"\n",
    "\n",
    "# Destination folders\n",
    "image_output_dir = r\"D:\\ShailyDL\\DeepL\\NEW_DS_Cleaned1\\images\"\n",
    "label_output_dir = r\"D:\\ShailyDL\\DeepL\\NEW_DS_Cleaned1\\labels\"\n",
    "\n",
    "# Create destination folders if they don't exist\n",
    "os.makedirs(image_output_dir, exist_ok=True)\n",
    "os.makedirs(label_output_dir, exist_ok=True)\n",
    "\n",
    "# Regex: Match only Dxxx or Dxxx_aug variants\n",
    "pattern = re.compile(r'(D\\d+(?:_aug\\d*)?)', re.IGNORECASE)\n",
    "\n",
    "def rename_and_copy_files(input_dir, output_dir, is_label=False):\n",
    "    count = 0\n",
    "    for file in os.listdir(input_dir):\n",
    "        match = pattern.search(file)\n",
    "        if match:\n",
    "            matched_part = match.group(1)\n",
    "            ext = \".txt\" if is_label else os.path.splitext(file)[1]\n",
    "            new_name = matched_part + ext\n",
    "            src = os.path.join(input_dir, file)\n",
    "            dst = os.path.join(output_dir, new_name)\n",
    "\n",
    "            # Avoid overwrite by appending suffix if needed\n",
    "            suffix = 1\n",
    "            while os.path.exists(dst):\n",
    "                new_name = f\"{matched_part}_{suffix}{ext}\"\n",
    "                dst = os.path.join(output_dir, new_name)\n",
    "                suffix += 1\n",
    "\n",
    "            shutil.copy2(src, dst)\n",
    "            count += 1\n",
    "        else:\n",
    "            print(f\"⚠️ No match found in filename: {file}\")\n",
    "    return count\n",
    "\n",
    "# Process files\n",
    "images_copied = rename_and_copy_files(image_input_dir, image_output_dir, is_label=False)\n",
    "labels_copied = rename_and_copy_files(label_input_dir, label_output_dir, is_label=True)\n",
    "\n",
    "print(\"✅ Done renaming and copying only Dxxx files.\")\n",
    "print(f\"Total images processed: {images_copied}\")\n",
    "print(f\"Total labels processed: {labels_copied}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bfdf4aa-6263-45b8-bb63-1aa68c0120e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done renaming and copying files.\n",
      "🧱 Crack-only images      : 100\n",
      "🪨 Delamination-only images : 377\n",
      "🔀 Mixed (both) images     : 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Input folders\n",
    "image_dir = r\"D:\\ShailyDL\\DeepL\\FilteredOut\\images\"\n",
    "label_dir = r\"D:\\ShailyDL\\DeepL\\FilteredOut\\labels\"\n",
    "\n",
    "# Output folders\n",
    "output_image_dir = r\"D:\\ShailyDL\\DeepL\\Cleaned_Categorized\\images\"\n",
    "output_label_dir = r\"D:\\ShailyDL\\DeepL\\Cleaned_Categorized\\labels\"\n",
    "\n",
    "os.makedirs(output_image_dir, exist_ok=True)\n",
    "os.makedirs(output_label_dir, exist_ok=True)\n",
    "\n",
    "# Starting counters\n",
    "crack_counter = 1031\n",
    "delam_counter = 660\n",
    "both_counter = 1\n",
    "\n",
    "# Class-wise counts\n",
    "crack_count = 0\n",
    "delam_count = 0\n",
    "both_count = 0\n",
    "\n",
    "# Supported image formats\n",
    "valid_exts = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "for img_file in os.listdir(image_dir):\n",
    "    if not img_file.lower().endswith(valid_exts):\n",
    "        continue\n",
    "\n",
    "    base_name = os.path.splitext(img_file)[0]\n",
    "    label_file = base_name + \".txt\"\n",
    "    label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "    if not os.path.exists(label_path):\n",
    "        print(f\"❌ Missing label file for {img_file}\")\n",
    "        continue\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        labels = [line.strip().split()[0] for line in f if line.strip()]\n",
    "        unique_classes = set(labels)\n",
    "\n",
    "    # Determine class and assign new name\n",
    "    if unique_classes == {'1'}:\n",
    "        new_base = f\"C{crack_counter}\"\n",
    "        crack_counter += 1\n",
    "        crack_count += 1\n",
    "    elif unique_classes == {'0'}:\n",
    "        new_base = f\"D{delam_counter}\"\n",
    "        delam_counter += 1\n",
    "        delam_count += 1\n",
    "    else:\n",
    "        new_base = f\"both{both_counter}\"\n",
    "        both_counter += 1\n",
    "        both_count += 1\n",
    "\n",
    "    # File extensions\n",
    "    ext = os.path.splitext(img_file)[1]\n",
    "\n",
    "    # Paths\n",
    "    src_img_path = os.path.join(image_dir, img_file)\n",
    "    src_lbl_path = os.path.join(label_dir, label_file)\n",
    "    dst_img_path = os.path.join(output_image_dir, new_base + ext)\n",
    "    dst_lbl_path = os.path.join(output_label_dir, new_base + \".txt\")\n",
    "\n",
    "    # Copy\n",
    "    shutil.copy2(src_img_path, dst_img_path)\n",
    "    shutil.copy2(src_lbl_path, dst_lbl_path)\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n✅ Done renaming and copying files.\")\n",
    "print(f\"🧱 Crack-only images      : {crack_count}\")\n",
    "print(f\"🪨 Delamination-only images : {delam_count}\")\n",
    "print(f\"🔀 Mixed (both) images     : {both_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "121c4b71-3cf7-4bdd-9f86-8cd1b0c50b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟡 Crack count: 1011\n",
      "🔵 Delamination count: 1477\n",
      "⚪ No defect (empty labels): 1362\n",
      "❌ Missing label files: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Paths\n",
    "image_dir = r\"D:\\ShailyDL\\DeepL\\FINAL_DS\\images\"\n",
    "label_dir = r\"D:\\ShailyDL\\DeepL\\FINAL_DS\\labels\"\n",
    "\n",
    "# Counters\n",
    "crack_count = 0\n",
    "delam_count = 0\n",
    "nodefect_count = 0\n",
    "missing_label_files = 0\n",
    "\n",
    "# Image extensions\n",
    "valid_exts = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "# Check each image\n",
    "for img_file in os.listdir(image_dir):\n",
    "    if not img_file.lower().endswith(valid_exts):\n",
    "        continue\n",
    "\n",
    "    base_name = os.path.splitext(img_file)[0]\n",
    "    label_file = base_name + '.txt'\n",
    "    label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "    if not os.path.exists(label_path):\n",
    "        missing_label_files += 1\n",
    "        continue\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        if not lines:\n",
    "            nodefect_count += 1\n",
    "        else:\n",
    "            classes = set(line.strip().split()[0] for line in lines if line.strip())\n",
    "            if '0' in classes:\n",
    "                crack_count += 1\n",
    "            if '1' in classes:\n",
    "                delam_count += 1\n",
    "\n",
    "print(f\"🟡 Crack count: {crack_count}\")\n",
    "print(f\"🔵 Delamination count: {delam_count}\")\n",
    "print(f\"⚪ No defect (empty labels): {nodefect_count}\")\n",
    "print(f\"❌ Missing label files: {missing_label_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23abfb66-09b9-4c2e-8328-6f6735befdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! Total images filtered out (not 2048x2048): 2984\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "# Source image and label folders\n",
    "source_image_folder = r\"D:\\ShailyDL\\DeepL\\FINAL_DS\\images\"\n",
    "source_label_folder = r\"D:\\ShailyDL\\DeepL\\FINAL_DS\\labels\"\n",
    "\n",
    "# Destination folders for filtered-out images and labels\n",
    "filtered_out_image_folder = r\"D:\\ShailyDL\\DeepL\\FilteredOut_Not_2048x2048\\images\"\n",
    "filtered_out_label_folder = r\"D:\\ShailyDL\\DeepL\\FilteredOut_Not_2048x2048\\labels\"\n",
    "\n",
    "os.makedirs(filtered_out_image_folder, exist_ok=True)\n",
    "os.makedirs(filtered_out_label_folder, exist_ok=True)\n",
    "\n",
    "mismatch_count = 0\n",
    "\n",
    "for filename in os.listdir(source_image_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "        image_path = os.path.join(source_image_folder, filename)\n",
    "        try:\n",
    "            with Image.open(image_path) as img:\n",
    "                width, height = img.size\n",
    "                if width != 2048 or height != 2048:\n",
    "                    # Move image to filtered-out images folder\n",
    "                    shutil.copy2(image_path, os.path.join(filtered_out_image_folder, filename))\n",
    "                    \n",
    "                    # Corresponding label file\n",
    "                    label_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "                    label_path = os.path.join(source_label_folder, label_filename)\n",
    "\n",
    "                    if os.path.exists(label_path):\n",
    "                        shutil.copy2(label_path, os.path.join(filtered_out_label_folder, label_filename))\n",
    "                    else:\n",
    "                        print(f\"⚠️ Label file missing for image: {filename}\")\n",
    "\n",
    "                    mismatch_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error reading {filename}: {e}\")\n",
    "\n",
    "print(f\"✅ Done! Total images filtered out (not 2048x2048): {mismatch_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b768fb2-963d-4017-88d0-2b79ca1509c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "filtered_out_image_dir = r\"D:\\ShailyDL\\DeepL\\FilteredOut_Not_2048x2048\\images\"\n",
    "input_label_dir = r\"D:\\ShailyDL\\DeepL\\FilteredOut_Not_2048x2048\\labels\"\n",
    "\n",
    "output_image_dir = r\"D:\\ShailyDL\\DeepL\\FilteredOut_Processed\\images\"\n",
    "output_label_dir = r\"D:\\ShailyDL\\DeepL\\FilteredOut_Processed\\labels\"\n",
    "\n",
    "os.makedirs(output_image_dir, exist_ok=True)\n",
    "os.makedirs(output_label_dir, exist_ok=True)\n",
    "\n",
    "TARGET_SIZE = 2048\n",
    "PADDING_COLOR = (0, 0, 0)\n",
    "\n",
    "def resize_and_pad_image(image):\n",
    "    h, w = image.shape[:2]\n",
    "    scale = min(TARGET_SIZE / w, TARGET_SIZE / h)\n",
    "    resized = cv2.resize(image, (int(w * scale), int(h * scale)))\n",
    "    new_h, new_w = resized.shape[:2]\n",
    "    pad_top = (TARGET_SIZE - new_h) // 2\n",
    "    pad_bottom = TARGET_SIZE - new_h - pad_top\n",
    "    pad_left = (TARGET_SIZE - new_w) // 2\n",
    "    pad_right = TARGET_SIZE - new_w - pad_left\n",
    "    padded = cv2.copyMakeBorder(resized, pad_top, pad_bottom, pad_left, pad_right,\n",
    "                                borderType=cv2.BORDER_CONSTANT, value=PADDING_COLOR)\n",
    "    return padded, scale, pad_left, pad_top, w, h\n",
    "\n",
    "def adjust_yolo_labels(label_path, output_path, scale, pad_left, pad_top, orig_w, orig_h):\n",
    "    if not os.path.exists(label_path):\n",
    "        print(f\"⚠️ Label file not found for {os.path.basename(label_path)}. Creating empty label file.\")\n",
    "        open(output_path, 'w').close()\n",
    "        return\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    updated_lines = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5:\n",
    "            continue\n",
    "        cls, x_center, y_center, box_w, box_h = map(float, parts)\n",
    "        abs_x = x_center * orig_w\n",
    "        abs_y = y_center * orig_h\n",
    "        abs_w = box_w * orig_w\n",
    "        abs_h = box_h * orig_h\n",
    "        abs_x = abs_x * scale + pad_left\n",
    "        abs_y = abs_y * scale + pad_top\n",
    "        abs_w *= scale\n",
    "        abs_h *= scale\n",
    "        rel_x = abs_x / TARGET_SIZE\n",
    "        rel_y = abs_y / TARGET_SIZE\n",
    "        rel_w = abs_w / TARGET_SIZE\n",
    "        rel_h = abs_h / TARGET_SIZE\n",
    "        updated_line = f\"{int(cls)} {rel_x:.6f} {rel_y:.6f} {rel_w:.6f} {rel_h:.6f}\"\n",
    "        updated_lines.append(updated_line)\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('\\n'.join(updated_lines))\n",
    "\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff']\n",
    "\n",
    "processed_count = 0\n",
    "\n",
    "for filename in os.listdir(filtered_out_image_dir):\n",
    "    if not any(filename.lower().endswith(ext) for ext in image_extensions):\n",
    "        continue\n",
    "    image_path = os.path.join(filtered_out_image_dir, filename)\n",
    "    label_path = os.path.join(input_label_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "    print(f\"Processing image: {filename}\")\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"⚠️ Could not read image {filename}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    padded_img, scale, pad_left, pad_top, orig_w, orig_h = resize_and_pad_image(img)\n",
    "\n",
    "    out_img_path = os.path.join(output_image_dir, filename)\n",
    "    out_label_path = os.path.join(output_label_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "\n",
    "    cv2.imwrite(out_img_path, padded_img)\n",
    "    adjust_yolo_labels(label_path, out_label_path, scale, pad_left, pad_top, orig_w, orig_h)\n",
    "\n",
    "    print(f\"✅ Saved processed image and label for {filename}\")\n",
    "    processed_count += 1\n",
    "\n",
    "print(f\"✅ Done! Processed {processed_count} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "496e33b1-ac2f-4a34-8683-a1e0fdb0137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Could not load D50.png\n",
      "✅ Done! Visualized images saved with centered class names.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Input paths\n",
    "image_dir = r\"D:\\ShailyDL\\DeepL\\FINAL_DS\\images\"\n",
    "label_dir = r\"D:\\ShailyDL\\DeepL\\FINAL_DS\\labels\"\n",
    "\n",
    "# Output path\n",
    "output_vis_dir = r\"D:\\ShailyDL\\DeepL\\FINAL_DS\\Visualized\"\n",
    "os.makedirs(output_vis_dir, exist_ok=True)\n",
    "\n",
    "# Class mapping and color (OpenCV uses BGR)\n",
    "class_names = {0: \"Delamination\", 1: \"Crack\"}\n",
    "class_colors = {\n",
    "    0: (98, 0, 255),     # Delamination: Purple\n",
    "    1: (0, 238, 196),    # Crack: Aqua\n",
    "}\n",
    "\n",
    "# Loop through each image\n",
    "for filename in os.listdir(image_dir):\n",
    "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "    label_path = os.path.join(label_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"⚠️ Could not load {filename}\")\n",
    "        continue\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    present_classes = set()\n",
    "\n",
    "    # Draw bounding boxes if label exists\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                cls_id, x_center, y_center, bw, bh = map(float, parts)\n",
    "\n",
    "                cls_id = int(cls_id)\n",
    "                present_classes.add(cls_id)\n",
    "\n",
    "                box_color = class_colors.get(cls_id, (0, 255, 0))\n",
    "\n",
    "                # Convert YOLO -> absolute coords\n",
    "                cx, cy = int(x_center * w), int(y_center * h)\n",
    "                box_w, box_h = int(bw * w), int(bh * h)\n",
    "                x1 = int(cx - box_w / 2)\n",
    "                y1 = int(cy - box_h / 2)\n",
    "                x2 = int(cx + box_w / 2)\n",
    "                y2 = int(cy + box_h / 2)\n",
    "\n",
    "                # Draw bbox\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), box_color, 2)\n",
    "\n",
    "    # Show only the relevant class names in the center\n",
    "    if present_classes:\n",
    "        font_scale = 2\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_thickness = 3\n",
    "        text_color = (255, 255, 255)\n",
    "\n",
    "        # Compose label string\n",
    "        text = \" | \".join([class_names[c] for c in sorted(present_classes)])\n",
    "        text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]\n",
    "        text_x = (w - text_size[0]) // 2\n",
    "        text_y = (h + text_size[1]) // 2\n",
    "\n",
    "        # Draw the text in the center\n",
    "        cv2.putText(img, text, (text_x, text_y), font, font_scale, text_color, font_thickness, cv2.LINE_AA)\n",
    "\n",
    "    # Save visualized image\n",
    "    out_path = os.path.join(output_vis_dir, filename)\n",
    "    cv2.imwrite(out_path, img)\n",
    "\n",
    "print(\"✅ Done! Visualized images saved with centered class names.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec31b82c-c977-4db9-9a2d-d7eace60a6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Renaming and swapping completed. Files saved in 'Swapped_Renamed' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Original folders\n",
    "input_img_dir = r\"D:\\ShailyDL\\DeepL\\FINAL_DS\\images\"\n",
    "input_lbl_dir = r\"D:\\ShailyDL\\DeepL\\FINAL_DS\\labels\"\n",
    "\n",
    "# Output folders\n",
    "output_img_dir = r\"D:\\ShailyDL\\DeepL\\Swapped_Renamed\\images\"\n",
    "output_lbl_dir = r\"D:\\ShailyDL\\DeepL\\Swapped_Renamed\\labels\"\n",
    "\n",
    "os.makedirs(output_img_dir, exist_ok=True)\n",
    "os.makedirs(output_lbl_dir, exist_ok=True)\n",
    "\n",
    "# --- Phase 1: C1031–C1130 → rename to D660–D759\n",
    "c_start, c_end = 1031, 1130\n",
    "d_start_new = 660\n",
    "\n",
    "for i, c_id in enumerate(range(c_start, c_end + 1)):\n",
    "    old_prefix = f\"C{c_id}\"\n",
    "    new_prefix = f\"D{d_start_new + i}\"\n",
    "\n",
    "    for ext in ['.jpg', '.png', '.jpeg']:\n",
    "        old_img_path = os.path.join(input_img_dir, old_prefix + ext)\n",
    "        if os.path.exists(old_img_path):\n",
    "            new_img_path = os.path.join(output_img_dir, new_prefix + ext)\n",
    "            shutil.copy2(old_img_path, new_img_path)\n",
    "            break  # use only first matching extension\n",
    "\n",
    "    old_lbl_path = os.path.join(input_lbl_dir, old_prefix + \".txt\")\n",
    "    new_lbl_path = os.path.join(output_lbl_dir, new_prefix + \".txt\")\n",
    "    if os.path.exists(old_lbl_path):\n",
    "        shutil.copy2(old_lbl_path, new_lbl_path)\n",
    "\n",
    "# --- Phase 2: D660–D1036 → rename to C1031–C1407 (maintaining 1:1)\n",
    "d_start, d_end = 660, 1036\n",
    "c_start_new = 1031\n",
    "\n",
    "for i, d_id in enumerate(range(d_start, d_end + 1)):\n",
    "    old_prefix = f\"D{d_id}\"\n",
    "    new_prefix = f\"C{c_start_new + i}\"\n",
    "\n",
    "    for ext in ['.jpg', '.png', '.jpeg']:\n",
    "        old_img_path = os.path.join(input_img_dir, old_prefix + ext)\n",
    "        if os.path.exists(old_img_path):\n",
    "            new_img_path = os.path.join(output_img_dir, new_prefix + ext)\n",
    "            shutil.copy2(old_img_path, new_img_path)\n",
    "            break\n",
    "\n",
    "    old_lbl_path = os.path.join(input_lbl_dir, old_prefix + \".txt\")\n",
    "    new_lbl_path = os.path.join(output_lbl_dir, new_prefix + \".txt\")\n",
    "    if os.path.exists(old_lbl_path):\n",
    "        shutil.copy2(old_lbl_path, new_lbl_path)\n",
    "\n",
    "print(\"✅ Renaming and swapping completed. Files saved in 'Swapped_Renamed' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b7f75be-8546-43ef-b6f5-45696ee8725d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images...\n",
      "\n",
      "Crack: Original=1383, Augmented=92, Total=1475\n",
      "Delamination: Original=725, Augmented=284, Total=1009\n",
      "Both: Original=2, Augmented=0, Total=2\n",
      "NoDefect: Original=1362, Augmented=0, Total=1362\n",
      "\n",
      "Splitting datasets...\n",
      "\n",
      "Dataset split summary:\n",
      "Split   Class          Orig  Aug   Total\n",
      "Train   Crack          1149  77    1226 \n",
      "Val     Crack          165   11    176  \n",
      "Test    Crack          69    4     73   \n",
      "Train   Delamination   602   236   838  \n",
      "Val     Delamination   87    34    121  \n",
      "Test    Delamination   36    14    50   \n",
      "Train   Both           2     0     2    \n",
      "Val     Both           0     0     0    \n",
      "Test    Both           0     0     0    \n",
      "Train   NoDefect       1131  0     1131 \n",
      "Val     NoDefect       163   0     163  \n",
      "Test    NoDefect       68    0     68   \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "image_dir = r'D:\\ShailyDL\\DeepL\\FINAL_DS\\images'\n",
    "label_dir = r'D:\\ShailyDL\\DeepL\\FINAL_DS\\labels'  # unused here but kept for clarity\n",
    "\n",
    "# Split ratios\n",
    "test_ratio = 0.05\n",
    "val_ratio = 0.12\n",
    "train_ratio = 1 - test_ratio - val_ratio  # 0.83\n",
    "\n",
    "# Categories with prefixes (lowercase for easy matching)\n",
    "categories = {\n",
    "    \"Crack\": \"c\",\n",
    "    \"Delamination\": \"d\",\n",
    "    \"Both\": \"both\",  # assuming prefix \"both\" if any, else handle separately\n",
    "    \"NoDefect\": \"n\"\n",
    "}\n",
    "\n",
    "# Helper to detect augmented images\n",
    "def is_augmented(filename):\n",
    "    return \"_aug\" in filename.lower()\n",
    "\n",
    "# Detect category based on prefix ignoring case\n",
    "def get_category(filename):\n",
    "    fname = filename.lower()\n",
    "    for cat, prefix in categories.items():\n",
    "        if prefix == \"both\":\n",
    "            # Handle Both category logic if needed here\n",
    "            if fname.startswith(\"both\"):\n",
    "                return \"Both\"\n",
    "            continue\n",
    "        if fname.startswith(prefix):\n",
    "            return cat\n",
    "    # No prefix matched = NoDefect\n",
    "    return \"NoDefect\"\n",
    "\n",
    "# Read all images\n",
    "all_images = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Prepare dict for categorized images\n",
    "category_files = {cat: {\"original\": [], \"augmented\": []} for cat in categories}\n",
    "\n",
    "# Categorize images\n",
    "for img in all_images:\n",
    "    cat = get_category(img)\n",
    "    if is_augmented(img):\n",
    "        category_files[cat][\"augmented\"].append(img)\n",
    "    else:\n",
    "        category_files[cat][\"original\"].append(img)\n",
    "\n",
    "# Print counts before splitting\n",
    "print(\"Processing images...\\n\")\n",
    "\n",
    "for cat in categories:\n",
    "    orig = len(category_files[cat][\"original\"])\n",
    "    aug = len(category_files[cat][\"augmented\"])\n",
    "    total = orig + aug\n",
    "    print(f\"{cat}: Original={orig}, Augmented={aug}, Total={total}\")\n",
    "\n",
    "# Function to split list\n",
    "def split_list(items):\n",
    "    random.shuffle(items)\n",
    "    n = len(items)\n",
    "    n_test = int(n * test_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "    n_train = n - n_val - n_test\n",
    "    return items[:n_train], items[n_train:n_train+n_val], items[n_train+n_val:]\n",
    "\n",
    "print(\"\\nSplitting datasets...\\n\")\n",
    "\n",
    "summary = []\n",
    "\n",
    "for cat in categories:\n",
    "    orig = category_files[cat][\"original\"]\n",
    "    aug = category_files[cat][\"augmented\"]\n",
    "\n",
    "    orig_train, orig_val, orig_test = split_list(orig)\n",
    "    aug_train, aug_val, aug_test = split_list(aug)\n",
    "\n",
    "    summary.append((cat, \"Train\", len(orig_train), len(aug_train), len(orig_train)+len(aug_train)))\n",
    "    summary.append((cat, \"Val\", len(orig_val), len(aug_val), len(orig_val)+len(aug_val)))\n",
    "    summary.append((cat, \"Test\", len(orig_test), len(aug_test), len(orig_test)+len(aug_test)))\n",
    "\n",
    "print(\"Dataset split summary:\")\n",
    "print(f\"{'Split':<7} {'Class':<14} {'Orig':<5} {'Aug':<5} {'Total':<5}\")\n",
    "for cat, split, orig_c, aug_c, total_c in summary:\n",
    "    print(f\"{split:<7} {cat:<14} {orig_c:<5} {aug_c:<5} {total_c:<5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac66026-0789-4c00-b2ef-3ec33e666f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images...\n",
      "\n",
      "Crack: Original=1383, Augmented=0, Total=1383\n",
      "Delamination: Original=725, Augmented=0, Total=725\n",
      "Both: Original=2, Augmented=0, Total=2\n",
      "NoDefect: Original=1362, Augmented=0, Total=1362\n",
      "\n",
      "Splitting datasets and copying files...\n",
      "\n",
      "\n",
      "✅ Dataset split summary:\n",
      "Split   Class          Orig  Aug   Total\n",
      "Train   Crack          1149  0     1149 \n",
      "Val     Crack          165   0     165  \n",
      "Test    Crack          69    0     69   \n",
      "Train   Delamination   602   0     602  \n",
      "Val     Delamination   87    0     87   \n",
      "Test    Delamination   36    0     36   \n",
      "Train   Both           2     0     2    \n",
      "Val     Both           0     0     0    \n",
      "Test    Both           0     0     0    \n",
      "Train   NoDefect       1131  0     1131 \n",
      "Val     NoDefect       163   0     163  \n",
      "Test    NoDefect       68    0     68   \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "image_dir = r'D:\\ShailyDL\\DeepL\\FINAL_DSw488\\images'\n",
    "label_dir = r'D:\\ShailyDL\\DeepL\\FINAL_DSw488\\labels'\n",
    "output_base_dir = r'D:\\ShailyDL\\DeepL\\FINAL_DS_Splitw488'\n",
    "\n",
    "# Split ratios\n",
    "test_ratio = 0.05\n",
    "val_ratio = 0.12\n",
    "train_ratio = 1 - test_ratio - val_ratio  # 0.83\n",
    "\n",
    "# Categories with prefixes (lowercase for easy matching)\n",
    "categories = {\n",
    "    \"Crack\": \"c\",\n",
    "    \"Delamination\": \"d\",\n",
    "    \"Both\": \"both\",\n",
    "    \"NoDefect\": \"n\"\n",
    "}\n",
    "\n",
    "# Helper to detect augmented images\n",
    "def is_augmented(filename):\n",
    "    return \"_aug\" in filename.lower()\n",
    "\n",
    "# Detect category based on prefix ignoring case\n",
    "def get_category(filename):\n",
    "    fname = filename.lower()\n",
    "    for cat, prefix in categories.items():\n",
    "        if prefix == \"both\":\n",
    "            if fname.startswith(\"both\"):\n",
    "                return \"Both\"\n",
    "            continue\n",
    "        if fname.startswith(prefix):\n",
    "            return cat\n",
    "    return \"NoDefect\"\n",
    "\n",
    "# Read all images\n",
    "all_images = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Prepare dict for categorized images\n",
    "category_files = {cat: {\"original\": [], \"augmented\": []} for cat in categories}\n",
    "\n",
    "# Categorize images\n",
    "for img in all_images:\n",
    "    cat = get_category(img)\n",
    "    if is_augmented(img):\n",
    "        category_files[cat][\"augmented\"].append(img)\n",
    "    else:\n",
    "        category_files[cat][\"original\"].append(img)\n",
    "\n",
    "# Print counts before splitting\n",
    "print(\"Processing images...\\n\")\n",
    "for cat in categories:\n",
    "    orig = len(category_files[cat][\"original\"])\n",
    "    aug = len(category_files[cat][\"augmented\"])\n",
    "    total = orig + aug\n",
    "    print(f\"{cat}: Original={orig}, Augmented={aug}, Total={total}\")\n",
    "\n",
    "# Function to split list\n",
    "def split_list(items):\n",
    "    random.shuffle(items)\n",
    "    n = len(items)\n",
    "    n_test = int(n * test_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "    n_train = n - n_val - n_test\n",
    "    return items[:n_train], items[n_train:n_train+n_val], items[n_train+n_val:]\n",
    "\n",
    "print(\"\\nSplitting datasets and copying files...\\n\")\n",
    "\n",
    "summary = []\n",
    "splits = {'train': [], 'val': [], 'test': []}\n",
    "\n",
    "for cat in categories:\n",
    "    orig = category_files[cat][\"original\"]\n",
    "    aug = category_files[cat][\"augmented\"]\n",
    "\n",
    "    orig_train, orig_val, orig_test = split_list(orig)\n",
    "    aug_train, aug_val, aug_test = split_list(aug)\n",
    "\n",
    "    splits['train'].extend(orig_train + aug_train)\n",
    "    splits['val'].extend(orig_val + aug_val)\n",
    "    splits['test'].extend(orig_test + aug_test)\n",
    "\n",
    "    summary.append((cat, \"Train\", len(orig_train), len(aug_train), len(orig_train)+len(aug_train)))\n",
    "    summary.append((cat, \"Val\", len(orig_val), len(aug_val), len(orig_val)+len(aug_val)))\n",
    "    summary.append((cat, \"Test\", len(orig_test), len(aug_test), len(orig_test)+len(aug_test)))\n",
    "\n",
    "# Create folders and copy files\n",
    "for split in ['train', 'val', 'test']:\n",
    "    img_output = os.path.join(output_base_dir, 'images', split)\n",
    "    lbl_output = os.path.join(output_base_dir, 'labels', split)\n",
    "    os.makedirs(img_output, exist_ok=True)\n",
    "    os.makedirs(lbl_output, exist_ok=True)\n",
    "\n",
    "    for fname in splits[split]:\n",
    "        src_img = os.path.join(image_dir, fname)\n",
    "        dst_img = os.path.join(img_output, fname)\n",
    "        shutil.copyfile(src_img, dst_img)\n",
    "\n",
    "        lbl_name = os.path.splitext(fname)[0] + \".txt\"\n",
    "        src_lbl = os.path.join(label_dir, lbl_name)\n",
    "        dst_lbl = os.path.join(lbl_output, lbl_name)\n",
    "        if os.path.exists(src_lbl):\n",
    "            shutil.copyfile(src_lbl, dst_lbl)\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: Label not found for image {fname}\")\n",
    "\n",
    "# Final summary print\n",
    "print(\"\\n✅ Dataset split summary:\")\n",
    "print(f\"{'Split':<7} {'Class':<14} {'Orig':<5} {'Aug':<5} {'Total':<5}\")\n",
    "for cat, split, orig_c, aug_c, total_c in summary:\n",
    "    print(f\"{split:<7} {cat:<14} {orig_c:<5} {aug_c:<5} {total_c:<5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6f599-2bf8-4493-8ff7-d3c1dea82fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
