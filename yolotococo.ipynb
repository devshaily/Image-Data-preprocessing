{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d41c4f-ecb1-4367-9850-bb992aaa0794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# Define YOLO dataset base path and COCO output path\n",
    "yolo_base = '/path/to/yolo/dataset'\n",
    "coco_output = '/path/to/coco/output'\n",
    "\n",
    "# Define categories (update the names accordingly)\n",
    "categories = [\n",
    "    {\"id\": 0, \"name\": \"delamination\"},\n",
    "    {\"id\": 1, \"name\": \"crack\"}\n",
    "]\n",
    "\n",
    "# Convert a YOLO split (train/val/test) to COCO format\n",
    "def convert_split(split_name):\n",
    "    image_dir = os.path.join(yolo_base, split_name, 'images')\n",
    "    label_dir = os.path.join(yolo_base, split_name, 'labels')\n",
    "\n",
    "    coco = {\n",
    "        \"info\": {},\n",
    "        \"licenses\": [],\n",
    "        \"categories\": categories,\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "\n",
    "    ann_id = 0\n",
    "    for img_id, image_file in enumerate(os.listdir(image_dir)):\n",
    "        if not image_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            continue\n",
    "        \n",
    "        img_path = os.path.join(image_dir, image_file)\n",
    "        label_path = os.path.join(label_dir, os.path.splitext(image_file)[0] + \".txt\")\n",
    "        \n",
    "        # Read image\n",
    "        image = Image.open(img_path)\n",
    "        width, height = image.size\n",
    "        \n",
    "        # Add image metadata\n",
    "        coco[\"images\"].append({\n",
    "            \"id\": img_id,\n",
    "            \"file_name\": image_file,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            continue\n",
    "\n",
    "        # Read corresponding label\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                class_id, x_center, y_center, w, h = map(float, parts)\n",
    "\n",
    "                x = (x_center - w / 2) * width\n",
    "                y = (y_center - h / 2) * height\n",
    "                bbox_width = w * width\n",
    "                bbox_height = h * height\n",
    "\n",
    "                coco[\"annotations\"].append({\n",
    "                    \"id\": ann_id,\n",
    "                    \"image_id\": img_id,\n",
    "                    \"category_id\": int(class_id),\n",
    "                    \"bbox\": [x, y, bbox_width, bbox_height],\n",
    "                    \"area\": bbox_width * bbox_height,\n",
    "                    \"iscrowd\": 0\n",
    "                })\n",
    "                ann_id += 1\n",
    "\n",
    "    # Save to JSON\n",
    "    os.makedirs(os.path.join(coco_output, 'annotations'), exist_ok=True)\n",
    "    with open(os.path.join(coco_output, 'annotations', f'{split_name}.json'), 'w') as f:\n",
    "        json.dump(coco, f, indent=2)\n",
    "\n",
    "# Convert each split\n",
    "for split in ['train', 'val', 'test']:\n",
    "    convert_split(split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9059dc-69df-4aed-880f-4ef73dae51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Directories for images and labels\n",
    "image_dir = 'D:/ShailyDL/DeepL/final_split_dataset2/test/images'\n",
    "label_dir = 'D:/ShailyDL/DeepL/final_split_dataset2/test/labels'\n",
    "\n",
    "# Regex pattern to match filenames like *_C39.jpg (for crack)\n",
    "pattern = re.compile(r\".*_C\\d+.*\\.(?:jpg|jpeg|png|bmp|gif|webp)$\", re.IGNORECASE)\n",
    "\n",
    "# Get matched crack images\n",
    "matched_images = [f for f in os.listdir(image_dir) if pattern.search(f.strip())]\n",
    "matched_images.sort()\n",
    "\n",
    "# Start renaming\n",
    "for idx, image_name in enumerate(matched_images, start=1):\n",
    "    name_base, ext = os.path.splitext(image_name)\n",
    "    \n",
    "    # Replace '_C' with '_D' to generate the label name for delamination if needed\n",
    "    label_name = name_base + \".txt\"\n",
    "    label_path = os.path.join(label_dir, label_name)\n",
    "\n",
    "    # New base name\n",
    "    new_base = str(idx)\n",
    "\n",
    "    # Paths for renaming image\n",
    "    old_image_path = os.path.join(image_dir, image_name)\n",
    "    new_image_path = os.path.join(image_dir, new_base + ext.lower())\n",
    "\n",
    "    # Rename image\n",
    "    os.rename(old_image_path, new_image_path)\n",
    "\n",
    "    # Rename label if exists\n",
    "    if os.path.exists(label_path):\n",
    "        new_label_path = os.path.join(label_dir, new_base + \".txt\")\n",
    "        os.rename(label_path, new_label_path)\n",
    "    else:\n",
    "        # If label file doesn't exist as is, try '_D' variant\n",
    "        delam_label_name = name_base.replace(\"_C\", \"_D\") + \".txt\"\n",
    "        delam_label_path = os.path.join(label_dir, delam_label_name)\n",
    "\n",
    "        if os.path.exists(delam_label_path):\n",
    "            new_label_path = os.path.join(label_dir, new_base + \".txt\")\n",
    "            os.rename(delam_label_path, new_label_path)\n",
    "        else:\n",
    "            print(f\"⚠️  Label not found for image: {image_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b13f3f8-d907-47f4-b721-48a08d3ca908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow\n",
      "  Downloading pillow-11.2.1-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
      "Downloading pillow-11.2.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 10.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pillow\n",
      "Successfully installed pillow-11.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e125f0-2935-4363-8a99-80ac1f74b195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: D:\\ShailyDL\\DeepL\\FINAL_DS_Split - Copy\\train\\images does not exist. Skipping...\n",
      "Warning: D:\\ShailyDL\\DeepL\\FINAL_DS_Split - Copy\\val\\images does not exist. Skipping...\n",
      "Warning: D:\\ShailyDL\\DeepL\\FINAL_DS_Split - Copy\\test\\images does not exist. Skipping...\n",
      "\n",
      "Conversion complete! Results saved to:\n",
      "coco_output\\annotations.json\n",
      "Total images: 0\n",
      "Total annotations: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "# Configuration\n",
    "BASE_PATH = 'D:/ShailyDL/DeepL/final_split_dataset2'  # Update this path\n",
    "BASE_PATH = 'D:/ShailyDL/DeepL/final_split_dataset2'\n",
    "\n",
    "OUTPUT_DIR = 'coco_output'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# COCO dataset categories (must start from 1)\n",
    "CATEGORIES = [\n",
    "    {\"id\": 1, \"name\": \"delamination\"},\n",
    "    {\"id\": 2, \"name\": \"crack\"}\n",
    "]\n",
    "\n",
    "# YOLO to COCO class ID mapping\n",
    "CATEGORY_MAP = {\n",
    "    0: 1,  # YOLO class 0 → COCO class 1 (delamination)\n",
    "    1: 2   # YOLO class 1 → COCO class 2 (crack)\n",
    "}\n",
    "\n",
    "# Initialize COCO dataset structure\n",
    "coco_output = {\n",
    "    \"info\": {\"description\": \"YOLO to COCO converted dataset\"},\n",
    "    \"licenses\": [],\n",
    "    \"categories\": CATEGORIES,\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n",
    "\n",
    "# Regex pattern to match valid image files\n",
    "IMAGE_PATTERN = re.compile(r\".*_[CD]\\d+.*\\.(?:jpg|jpeg|png|bmp|gif|webp)$\", re.IGNORECASE)\n",
    "\n",
    "def convert_yolo_to_coco():\n",
    "    image_id = 0\n",
    "    annotation_id = 0\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        image_dir = os.path.join(BASE_PATH, split, 'images')\n",
    "        label_dir = os.path.join(BASE_PATH, split, 'labels')\n",
    "\n",
    "        if not os.path.exists(image_dir):\n",
    "            print(f\"Warning: {image_dir} does not exist. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(image_dir):\n",
    "            if not IMAGE_PATTERN.search(filename):\n",
    "                continue\n",
    "\n",
    "            # Process image\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            try:\n",
    "                with Image.open(image_path) as img:\n",
    "                    width, height = img.size\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {image_path}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "            # Add image metadata to COCO\n",
    "            coco_output[\"images\"].append({\n",
    "                \"id\": image_id,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"file_name\": os.path.join(split, \"images\", filename).replace(\"\\\\\", \"/\"),\n",
    "                \"split\": split\n",
    "            })\n",
    "\n",
    "            # Process corresponding label file\n",
    "            label_path = os.path.join(label_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "            if not os.path.exists(label_path):\n",
    "                print(f\"Warning: Missing label file for {filename}\")\n",
    "                continue\n",
    "\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line_num, line in enumerate(f, 1):\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) != 5:\n",
    "                        print(f\"Invalid annotation in {label_path}, line {line_num}: '{line.strip()}'\")\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        cls, x_center, y_center, box_w, box_h = map(float, parts)\n",
    "                        cls = int(cls)\n",
    "\n",
    "                        # Convert YOLO to COCO bbox format [x_min, y_min, width, height]\n",
    "                        x_min = round((x_center - box_w/2) * width)\n",
    "                        y_min = round((y_center - box_h/2) * height)\n",
    "                        width_px = round(box_w * width)\n",
    "                        height_px = round(box_h * height)\n",
    "\n",
    "                        # Ensure coordinates are within image bounds\n",
    "                        x_min = max(0, x_min)\n",
    "                        y_min = max(0, y_min)\n",
    "                        width_px = min(width - x_min, width_px)\n",
    "                        height_px = min(height - y_min, height_px)\n",
    "\n",
    "                        if width_px <= 0 or height_px <= 0:\n",
    "                            print(f\"Invalid bbox in {label_path}, line {line_num}: {line.strip()}\")\n",
    "                            continue\n",
    "\n",
    "                        coco_output[\"annotations\"].append({\n",
    "                            \"id\": annotation_id,\n",
    "                            \"image_id\": image_id,\n",
    "                            \"category_id\": CATEGORY_MAP[cls],\n",
    "                            \"bbox\": [x_min, y_min, width_px, height_px],\n",
    "                            \"area\": width_px * height_px,\n",
    "                            \"iscrowd\": 0\n",
    "                        })\n",
    "                        annotation_id += 1\n",
    "\n",
    "                    except (ValueError, KeyError) as e:\n",
    "                        print(f\"Error processing {label_path}, line {line_num}: {str(e)}\")\n",
    "\n",
    "            image_id += 1\n",
    "\n",
    "    # Save COCO JSON\n",
    "    output_path = os.path.join(OUTPUT_DIR, 'annotations.json')\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(coco_output, f, indent=4)\n",
    "\n",
    "    print(f\"\\nConversion complete! Results saved to:\\n{output_path}\")\n",
    "    print(f\"Total images: {len(coco_output['images'])}\")\n",
    "    print(f\"Total annotations: {len(coco_output['annotations'])}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert_yolo_to_coco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390bd9a0-8b45-46c6-ae06-1b3a16a59742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! Separate JSONs created for train/val/test.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "BASE_PATH = 'D:/Deep_Learning/Dataset/MRCNN/'\n",
    "OUTPUT_DIR = 'D:/Deep_Learning/Dataset/MRCNN/coco_output2'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CATEGORIES = [{\"id\": 1, \"name\": \"Delamination\"}, {\"id\": 2, \"name\": \"Crack\"}, {\"id\": 3, \"name\": \"Nodefect\"}]\n",
    "CATEGORY_MAP = {0: 1, 1: 2,  2: 3}  # YOLO to COCO class mapping\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    coco_data = {\n",
    "        \"info\": {},\n",
    "        \"licenses\": [],\n",
    "        \"categories\": CATEGORIES,\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    \n",
    "    image_dir = os.path.join(BASE_PATH, split, 'images')\n",
    "    label_dir = os.path.join(BASE_PATH, split, 'labels')\n",
    "    \n",
    "    image_id = 0\n",
    "    annotation_id = 0\n",
    "    \n",
    "    for img_file in os.listdir(image_dir):\n",
    "        if not img_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            continue\n",
    "        \n",
    "        # Load image\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size\n",
    "        \n",
    "        # Add image info\n",
    "        coco_data[\"images\"].append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": f\"{split}/images/{img_file}\",\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "        \n",
    "        # Load annotations\n",
    "        txt_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        txt_path = os.path.join(label_dir, txt_file)\n",
    "        \n",
    "        if os.path.exists(txt_path):\n",
    "            with open(txt_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) != 5:\n",
    "                        continue\n",
    "                    \n",
    "                    cls, x_center, y_center, w, h = map(float, parts)\n",
    "                    x_min = (x_center - w/2) * width\n",
    "                    y_min = (y_center - h/2) * height\n",
    "                    width_px = w * width\n",
    "                    height_px = h * height\n",
    "                    \n",
    "                    coco_data[\"annotations\"].append({\n",
    "                        \"id\": annotation_id,\n",
    "                        \"image_id\": image_id,\n",
    "                        \"category_id\": CATEGORY_MAP[int(cls)],\n",
    "                        \"bbox\": [x_min, y_min, width_px, height_px],\n",
    "                        \"area\": width_px * height_px,\n",
    "                        \"iscrowd\": 0\n",
    "                    })\n",
    "                    annotation_id += 1\n",
    "        \n",
    "        image_id += 1\n",
    "    \n",
    "    # Save per-split JSON\n",
    "    with open(f'{OUTPUT_DIR}/annotations_{split}.json', 'w') as f:\n",
    "        json.dump(coco_data, f, indent=2)\n",
    "\n",
    "print(\"Conversion complete! Separate JSONs created for train/val/test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a0cd180-def9-4d6a-bb1c-ed959d831a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp312-cp312-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ---------------------------------------  7.9/8.1 MB 44.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 38.4 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.2-cp312-cp312-win_amd64.whl (223 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 42.0 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91c80544-a753-4ad3-b094-9f440a096576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found annotations file: D:\\ShailyDL\\DeepL\\final_split_dataset_coco\\test\\images\\annotations_test.json\n",
      "Found 88 images in annotations\n",
      "\n",
      "Successfully processed 102 images\n",
      "Visualized images saved to: D:\\ShailyDL\\DeepL\\final_split_dataset_coco\\test\\visualized_bboxes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# Path configuration\n",
    "base_path = Path('D:/ShailyDL/DeepL/final_split_dataset_coco/test')\n",
    "images_dir = base_path / 'images'\n",
    "output_dir = base_path / 'visualized_bboxes'\n",
    "\n",
    "# Try to find annotations in images folder\n",
    "possible_annotation_names = [\n",
    "    'annotations_test.json',\n",
    "    'instances_test.json',\n",
    "    'test.json',\n",
    "    'annotations.json'\n",
    "]\n",
    "\n",
    "annotations_file = None\n",
    "for name in possible_annotation_names:\n",
    "    potential_path = images_dir / name\n",
    "    if potential_path.exists():\n",
    "        annotations_file = potential_path\n",
    "        break\n",
    "\n",
    "if not annotations_file:\n",
    "    available_files = [f.name for f in images_dir.glob('*') if f.is_file()]\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find annotations file in {images_dir}.\\n\"\n",
    "        f\"Tried: {possible_annotation_names}\\n\"\n",
    "        f\"Files present: {available_files}\"\n",
    "    )\n",
    "\n",
    "# Create output directory\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Load COCO annotations\n",
    "with open(annotations_file, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Rest of the processing...\n",
    "print(f\"Found annotations file: {annotations_file}\")\n",
    "print(f\"Found {len(coco_data['images'])} images in annotations\")\n",
    "\n",
    "# Create mapping from image_id to image info\n",
    "image_info = {img['id']: img for img in coco_data['images']}\n",
    "category_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
    "\n",
    "colors = {\n",
    "    1: (255, 0, 0),    # Red for delamination\n",
    "    2: (0, 0, 255)      # Blue for crack\n",
    "}\n",
    "\n",
    "processed_images = 0\n",
    "\n",
    "for ann in coco_data['annotations']:\n",
    "    img_id = ann['image_id']\n",
    "    img_info = image_info.get(img_id)\n",
    "    \n",
    "    if not img_info:\n",
    "        print(f\"Warning: No image info found for image_id {img_id}\")\n",
    "        continue\n",
    "\n",
    "    img_filename = Path(img_info['file_name']).name\n",
    "    img_path = images_dir / img_filename\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        print(f\"Warning: Image not found at {img_path}\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not load image {img_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Draw bounding box\n",
    "    bbox = ann['bbox']  # [x, y, width, height]\n",
    "    category_id = ann['category_id']\n",
    "    x, y, w, h = map(int, bbox)\n",
    "    \n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), colors[category_id], 2)\n",
    "    \n",
    "    # Add label text\n",
    "    label = category_info.get(category_id, str(category_id))\n",
    "    cv2.putText(img, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "               0.5, colors.get(category_id, (0,255,0)), 2)\n",
    "    \n",
    "    # Save visualized image\n",
    "    output_path = output_dir / img_filename\n",
    "    cv2.imwrite(str(output_path), img)\n",
    "    processed_images += 1\n",
    "\n",
    "print(f\"\\nSuccessfully processed {processed_images} images\")\n",
    "print(f\"Visualized images saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb36287-9dae-42d1-a19e-f995ac8a5dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! Separate JSONs created for train/val\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "BASE_PATH = 'D:/ShailyDL/DeepL/New_Detection_coco'\n",
    "OUTPUT_DIR = 'coco_outputorg'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CATEGORIES = [{\"id\": 1, \"name\": \"delamination\"}, {\"id\": 2, \"name\": \"crack\"}]\n",
    "CATEGORY_MAP = {0: 1, 1: 2}  # YOLO to COCO class mapping\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    coco_data = {\n",
    "        \"info\": {},\n",
    "        \"licenses\": [],\n",
    "        \"categories\": CATEGORIES,\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    \n",
    "    image_dir = os.path.join(BASE_PATH, split, 'images')\n",
    "    label_dir = os.path.join(BASE_PATH, split, 'labels')\n",
    "    \n",
    "    image_id = 0\n",
    "    annotation_id = 0\n",
    "    \n",
    "    for img_file in os.listdir(image_dir):\n",
    "        if not img_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            continue\n",
    "        \n",
    "        # Load image\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size\n",
    "        \n",
    "        # Add image info\n",
    "        coco_data[\"images\"].append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": f\"{split}/images/{img_file}\",\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "        \n",
    "        # Load annotations\n",
    "        txt_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        txt_path = os.path.join(label_dir, txt_file)\n",
    "        \n",
    "        if os.path.exists(txt_path):\n",
    "            with open(txt_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) != 5:\n",
    "                        continue\n",
    "                    \n",
    "                    cls, x_center, y_center, w, h = map(float, parts)\n",
    "                    x_min = (x_center - w/2) * width\n",
    "                    y_min = (y_center - h/2) * height\n",
    "                    width_px = w * width\n",
    "                    height_px = h * height\n",
    "                    \n",
    "                    coco_data[\"annotations\"].append({\n",
    "                        \"id\": annotation_id,\n",
    "                        \"image_id\": image_id,\n",
    "                        \"category_id\": CATEGORY_MAP[int(cls)],\n",
    "                        \"bbox\": [x_min, y_min, width_px, height_px],\n",
    "                        \"area\": width_px * height_px,\n",
    "                        \"iscrowd\": 0\n",
    "                    })\n",
    "                    annotation_id += 1\n",
    "        \n",
    "        image_id += 1\n",
    "    \n",
    "    # Save per-split JSON\n",
    "    with open(f'{OUTPUT_DIR}/annotations_{split}.json', 'w') as f:\n",
    "        json.dump(coco_data, f, indent=2)\n",
    "\n",
    "print(\"Conversion complete! Separate JSONs created for train/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11164e46-c159-46a9-8f0d-3f31b18d8db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
